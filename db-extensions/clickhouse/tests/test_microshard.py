import unittest
import os
import uuid
from datetime import datetime, timezone, timedelta
from clickhouse_driver import Client

# ==============================================================================
# CONFIGURATION
# ==============================================================================
CH_HOST = "localhost"
CH_PORT = 9000
CH_USER = "clickhouse"
CH_PASSWORD = "clickhouse"
CH_DB = "default"
SQL_FILE_PATH = os.path.join(os.path.dirname(__file__), "../microshard_uuid.sql")


class TestMicroShardUUIDExtended(unittest.TestCase):

    @classmethod
    def setUpClass(cls):
        """
        Reads the SQL file and applies the functions to the ClickHouse database.
        """
        cls.client = Client(
            host=CH_HOST,
            port=CH_PORT,
            user=CH_USER,
            password=CH_PASSWORD,
            database=CH_DB,
        )

        try:
            with open(SQL_FILE_PATH, "r") as f:
                sql_content = f.read()

            # Split by semicolon to execute individual CREATE statements
            statements = [s.strip() for s in sql_content.split(";") if s.strip()]

            for statement in statements:
                cls.client.execute(statement)
        except FileNotFoundError:
            raise RuntimeError(f"Could not find SQL file at {SQL_FILE_PATH}")

    # ==========================================================================
    # HELPER: Python "Golden" Implementation
    # ==========================================================================
    def python_calc_uuid_int(self, micros, shard_id):
        """
        Calculates the expected 128-bit Integer value of the UUID
        using Python's native Big-Endian math.
        """
        # 1. Construct High 64 Bits (Time + Ver + ShardHigh)
        time_high = (micros >> 6) & 0xFFFFFFFFFFFF
        version = 8
        time_low = micros & 0x3F
        shard_high = (shard_id >> 26) & 0x3F

        high_64 = (time_high << 16) | (version << 12) | (time_low << 6) | shard_high

        # 2. Construct Low 64 Bits (Var + ShardLow + Random)
        variant = 2  # Binary 10
        shard_low = shard_id & 0x3FFFFFF

        low_64_prefix = (variant << 62) | (shard_low << 36)

        return high_64, low_64_prefix

    # ==========================================================================
    # CORE TESTS
    # ==========================================================================

    def test_01_structural_integrity(self):
        """
        Verifies that the UUID bits generated by SQL match the Python specification exactly.
        """
        micros = 1698400800123456
        shard_id = 123456789

        sql = f"SELECT toString(microshard_from_micros({micros}, {shard_id}))"
        uuid_str = self.client.execute(sql)[0][0]
        u = uuid.UUID(uuid_str)

        exp_high, exp_low_prefix = self.python_calc_uuid_int(micros, shard_id)

        actual_high = u.int >> 64
        actual_low = u.int & 0xFFFFFFFFFFFFFFFF

        self.assertEqual(
            actual_high, exp_high, "High 64 bits (Time/ShardHigh) mismatch"
        )
        # Check top 28 bits of low part (Variant + ShardLow)
        self.assertEqual(
            actual_low >> 36,
            exp_low_prefix >> 36,
            "Low 64 bits prefix (Var/ShardLow) mismatch",
        )
        self.assertEqual(u.version, 8, "UUID Version must be 8")
        self.assertEqual(u.variant, uuid.RFC_4122, "UUID Variant must be RFC 4122")

    def test_02_round_trip_basic(self):
        """
        Verify that values put in come back out unchanged.
        """
        micros = 1700000000000000
        shard_id = 555

        sql = f"""
        WITH 
            microshard_from_micros({micros}, {shard_id}) AS uid,
            toUnixTimestamp64Micro(microshard_get_timestamp(uid)) AS out_micros,
            microshard_get_shard_id(uid) AS out_shard
        SELECT out_micros, out_shard
        """
        row = self.client.execute(sql)[0]
        self.assertEqual(row[0], micros)
        self.assertEqual(row[1], shard_id)

    # ==========================================================================
    # EDGE CASE TESTS
    # ==========================================================================

    def test_03_edge_epoch_time(self):
        """
        Test T=0 (1970-01-01 00:00:00).
        This ensures bit shifting doesn't fail on zero.
        """
        micros = 0
        shard_id = 1

        sql = f"""
        SELECT 
            microshard_get_iso_timestamp(microshard_from_micros({micros}, {shard_id})),
            microshard_get_shard_id(microshard_from_micros({micros}, {shard_id}))
        """
        row = self.client.execute(sql)[0]

        self.assertEqual(row[0], "1970-01-01T00:00:00.000000Z")
        self.assertEqual(row[1], shard_id)

    def test_04_edge_max_uint32_shard(self):
        """
        Test the Maximum possible 32-bit Shard ID (4,294,967,295).
        This verifies that all bits are preserved when splitting Shard ID
        across the High/Low UUID segments.
        """
        micros = 1600000000000000
        max_shard = 4294967295  # 2^32 - 1

        sql = f"SELECT microshard_get_shard_id(microshard_from_micros({micros}, {max_shard}))"
        result = self.client.execute(sql)[0][0]

        self.assertEqual(result, max_shard)

    def test_05_shard_split_boundary(self):
        """
        CRITICAL: Test the exact boundary where Shard ID bits move from
        the Low Qword to the High Qword.
        """
        # Case A: Max fits in Low Segment
        s1 = 67108863
        r1 = self.client.execute(
            f"SELECT microshard_get_shard_id(microshard_generate({s1}))"
        )[0][0]
        self.assertEqual(r1, s1, "Failed at 26-bit boundary (Max Low)")

        # Case B: First value to spill into High Segment
        s2 = 67108864
        r2 = self.client.execute(
            f"SELECT microshard_get_shard_id(microshard_generate({s2}))"
        )[0][0]
        self.assertEqual(r2, s2, "Failed at 26-bit boundary (First High)")

    def test_06_future_date_year_2100(self):
        """
        Test a far future date to ensure 48+6 bit timestamp logic holds up.
        """
        dt = datetime(2100, 1, 1, 12, 0, 0, tzinfo=timezone.utc)
        micros = int(dt.timestamp() * 1_000_000)
        shard_id = 99

        sql = f"SELECT microshard_get_iso_timestamp(microshard_from_micros({micros}, {shard_id}))"
        res = self.client.execute(sql)[0][0]

        self.assertEqual(res, "2100-01-01T12:00:00.000000Z")

    def test_07_sub_microsecond_precision(self):
        """
        Verify the ISO output handles microsecond padding correctly.
        """
        micros = 5
        shard_id = 1

        sql = f"SELECT microshard_get_iso_timestamp(microshard_from_micros({micros}, {shard_id}))"
        res = self.client.execute(sql)[0][0]

        self.assertEqual(res, "1970-01-01T00:00:00.000005Z")

    def test_08_sql_sorting_behavior(self):
        """
        Verify that SQL 'ORDER BY' sorts these UUIDs by Time first.
        """
        t1 = 1000000
        t2 = 2000000
        t3 = 3000000
        shard = 1

        sql = f"""
        SELECT uid FROM (
            SELECT microshard_from_micros({t2}, {shard}) as uid
            UNION ALL
            SELECT microshard_from_micros({t3}, {shard}) as uid
            UNION ALL
            SELECT microshard_from_micros({t1}, {shard}) as uid
        ) ORDER BY
            microshard_sort_key(uid)
        ASC
        """
        rows = self.client.execute(sql)

        u1 = uuid.UUID(str(rows[0][0]))
        u2 = uuid.UUID(str(rows[1][0]))
        u3 = uuid.UUID(str(rows[2][0]))

        self.assertLess(u1.int, u2.int)
        self.assertLess(u2.int, u3.int)

    def test_09_randomness_uniqueness_batch(self):
        """
        Generate 1000 UUIDs for the same Shard ID in a batch.
        Verify no collisions.
        """
        shard_id = 777
        count = 1000

        sql = f"""
        SELECT count(DISTINCT microshard_generate({shard_id})) 
        FROM numbers({count})
        """
        unique_count = self.client.execute(sql)[0][0]

        self.assertEqual(
            unique_count,
            count,
            f"Collisions detected! Generated {count}, found {unique_count} unique.",
        )

    def test_10_type_verification(self):
        """
        Ensure the function returns a native UUID type.
        """
        sql = "SELECT toTypeName(microshard_generate(1))"
        res = self.client.execute(sql)[0][0]
        self.assertEqual(res, "UUID", "Function must return UUID type")

    def test_11_edge_max_timestamp(self):
        """
        Test the Maximum supported 54-bit timestamp (Year 10889).

        CRITICAL: ClickHouse 'DateTime64' caps at Year 2299.
        We must use our new 'microshard_get_micros' function to verify
        values larger than this limit.
        """
        # (2^54) - 1 microseconds = approx Year 10889
        max_micros = 18_014_398_509_481_983
        shard_id = 999

        # 1. Generate UUID
        sql_gen = f"SELECT toString(microshard_from_micros({max_micros}, {shard_id}))"
        uuid_str = self.client.execute(sql_gen)[0][0]

        # 2. Extract Raw Microseconds (Bypassing DateTime64 cast)
        sql_extract = f"""
        SELECT microshard_get_micros(toUUID('{uuid_str}'))
        """
        extracted_micros = self.client.execute(sql_extract)[0][0]

        self.assertEqual(
            extracted_micros, max_micros, "Max 54-bit timestamp failed round trip"
        )

        # 3. Structural Check
        u = uuid.UUID(uuid_str)
        self.assertEqual(u.version, 8, "Version bits corrupted by large timestamp")


if __name__ == "__main__":
    unittest.main()
